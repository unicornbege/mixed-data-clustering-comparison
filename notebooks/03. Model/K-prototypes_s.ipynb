{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1f27947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbdcde71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students = pd.read_csv('/Users/althaaframadhan/Documents/Skripsi/Penelitian/preprocessing/students_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f070188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Gender Academic_Level     Country  Avg_Daily_Usage_Hours  \\\n",
      "0   20  Female  Undergraduate      France                    3.0   \n",
      "1   19  Female  Undergraduate  Azerbaijan                    4.8   \n",
      "2   22  Female       Graduate  Kyrgyzstan                    2.9   \n",
      "3   19  Female  Undergraduate  Bangladesh                    4.2   \n",
      "4   22    Male       Graduate     Germany                    3.1   \n",
      "\n",
      "  Most_Used_Platform Affects_Academic_Performance  Sleep_Hours_Per_Night  \\\n",
      "0          Instagram                           No                    9.0   \n",
      "1             TikTok                          Yes                    5.7   \n",
      "2           Facebook                           No                    7.0   \n",
      "3          Instagram                          Yes                    7.8   \n",
      "4           Facebook                           No                    8.4   \n",
      "\n",
      "   Mental_Health_Score  Conflicts_Over_Social_Media  Addicted_Score  \n",
      "0                    7                            2               5  \n",
      "1                    6                            3               7  \n",
      "2                    7                            2               5  \n",
      "3                    5                            3               7  \n",
      "4                    8                            1               4  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Age                           200 non-null    int64  \n",
      " 1   Gender                        200 non-null    object \n",
      " 2   Academic_Level                200 non-null    object \n",
      " 3   Country                       200 non-null    object \n",
      " 4   Avg_Daily_Usage_Hours         200 non-null    float64\n",
      " 5   Most_Used_Platform            200 non-null    object \n",
      " 6   Affects_Academic_Performance  200 non-null    object \n",
      " 7   Sleep_Hours_Per_Night         200 non-null    float64\n",
      " 8   Mental_Health_Score           200 non-null    int64  \n",
      " 9   Conflicts_Over_Social_Media   200 non-null    int64  \n",
      " 10  Addicted_Score                200 non-null    int64  \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 17.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_students.head())\n",
    "print(df_students.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad146e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['Age', 'Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night', 'Mental_Health_Score', 'Conflicts_Over_Social_Media', 'Addicted_Score']\n",
      "Categorical columns: ['Gender', 'Academic_Level', 'Country', 'Most_Used_Platform', 'Affects_Academic_Performance']\n"
     ]
    }
   ],
   "source": [
    "df = df_students.copy()\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60d87432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df.copy()\n",
    "cat_mappings = {}\n",
    "for col in cat_cols:\n",
    "    df_encoded[col], mapping = df[col].astype('category').factorize()\n",
    "    cat_mappings[col] = mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6276d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.to_numpy()\n",
    "num_idx = [df_encoded.columns.get_loc(col) for col in num_cols]\n",
    "cat_idx = [df_encoded.columns.get_loc(col) for col in cat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54cd02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_idx: [0, 4, 7, 8, 9, 10]\n",
      "cat_idx: [1, 2, 3, 5, 6]\n",
      "X.shape: (200, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"num_idx:\", num_idx)\n",
    "print(\"cat_idx:\", cat_idx)\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72d33d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma chosen = 1.2221218607038884\n"
     ]
    }
   ],
   "source": [
    "if len(num_idx) > 0:\n",
    "    gamma = float(np.nanmean(np.std(X[:, num_idx].astype(float), axis=0)))\n",
    "else:\n",
    "    gamma = 1.0\n",
    "print(\"gamma chosen =\", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87938187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_dissim(a, b, num_idx, cat_idx, gamma):\n",
    "    # numeric: Euclidean\n",
    "    if len(num_idx) > 0:\n",
    "        diff_num = a[num_idx].astype(float) - b[num_idx].astype(float)\n",
    "        num_dist = math.sqrt(np.sum(diff_num ** 2))\n",
    "    else:\n",
    "        num_dist = 0.0\n",
    "    # categorical: simple matching (count mismatches)\n",
    "    if len(cat_idx) > 0:\n",
    "        cat_dist = np.sum(a[cat_idx] != b[cat_idx])\n",
    "    else:\n",
    "        cat_dist = 0.0\n",
    "    return num_dist + gamma * cat_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "067277ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_mixed(X, labels, num_idx, cat_idx, gamma):\n",
    "    labels = np.array(labels)\n",
    "    n = X.shape[0]\n",
    "    unique_labels = np.unique(labels)\n",
    "    clusters = {lab: np.where(labels == lab)[0] for lab in unique_labels}\n",
    "    sil_vals = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        xi = X[i]\n",
    "        own = labels[i]\n",
    "        members = clusters[own]\n",
    "        if len(members) == 1:\n",
    "            a_i = 0.0\n",
    "        else:\n",
    "            others = members[members != i]\n",
    "            a_i = np.mean([mixed_dissim(xi, X[j], num_idx, cat_idx, gamma) for j in others])\n",
    "        b_vals = []\n",
    "        for lab in unique_labels:\n",
    "            if lab == own:\n",
    "                continue\n",
    "            mem = clusters[lab]\n",
    "            if len(mem)==0: continue\n",
    "            avg = np.mean([mixed_dissim(xi, X[j], num_idx, cat_idx, gamma) for j in mem])\n",
    "            b_vals.append(avg)\n",
    "        b_i = min(b_vals) if len(b_vals)>0 else 0.0\n",
    "        denom = max(a_i, b_i)\n",
    "        sil_vals[i] = 0.0 if denom==0 else (b_i - a_i) / denom\n",
    "    return np.mean(sil_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f92724a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_index_mixed(X, labels, num_idx, cat_idx, gamma):\n",
    "    labels = np.array(labels)\n",
    "    unique_labels = np.unique(labels)\n",
    "    # intra diameters\n",
    "    diameters = []\n",
    "    for lab in unique_labels:\n",
    "        members = np.where(labels==lab)[0]\n",
    "        if len(members) <= 1:\n",
    "            diameters.append(0.0)\n",
    "            continue\n",
    "        maxd = 0.0\n",
    "        for i in range(len(members)):\n",
    "            for j in range(i+1, len(members)):\n",
    "                d = mixed_dissim(X[members[i]], X[members[j]], num_idx, cat_idx, gamma)\n",
    "                if d > maxd:\n",
    "                    maxd = d\n",
    "        diameters.append(maxd)\n",
    "    max_diameter = max(diameters) if len(diameters)>0 else 0.0\n",
    "    # inter-cluster min distance\n",
    "    min_inter = float('inf')\n",
    "    for a, b in combinations(unique_labels, 2):\n",
    "        mem_a = np.where(labels==a)[0]\n",
    "        mem_b = np.where(labels==b)[0]\n",
    "        if len(mem_a)==0 or len(mem_b)==0:\n",
    "            continue\n",
    "        mind = float('inf')\n",
    "        for i in mem_a:\n",
    "            for j in mem_b:\n",
    "                d = mixed_dissim(X[i], X[j], num_idx, cat_idx, gamma)\n",
    "                if d < mind:\n",
    "                    mind = d\n",
    "        if mind < min_inter:\n",
    "            min_inter = mind\n",
    "    if max_diameter == 0 or min_inter==float('inf'):\n",
    "        return 0.0\n",
    "    return min_inter / max_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cb94db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting k=2 ...\n",
      "Fitting k=3 ...\n",
      "Fitting k=4 ...\n",
      "Fitting k=5 ...\n",
      "Fitting k=6 ...\n",
      "Fitting k=7 ...\n",
      "Fitting k=8 ...\n",
      "Fitting k=9 ...\n",
      "Fitting k=10 ...\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "labels_dict = {}\n",
    "max_k = 10 if X.shape[0] >= 10 else max(2, X.shape[0]-1)\n",
    "\n",
    "for k in range(2, max_k+1):\n",
    "    print(f\"Fitting k={k} ...\")\n",
    "    model = KPrototypes(n_clusters=k, init='random', max_iter=100, verbose=0, gamma=gamma)\n",
    "    clusters = model.fit_predict(X, categorical=cat_idx)\n",
    "    # cost (elbow)\n",
    "    cost = getattr(model, 'cost_', None)\n",
    "    if cost is None:\n",
    "        centroids = model.cluster_centroids_\n",
    "        cost = sum(mixed_dissim(X[i], centroids[clusters[i]], num_idx, cat_idx, gamma) for i in range(X.shape[0]))\n",
    "    sil = silhouette_mixed(X, clusters, num_idx, cat_idx, gamma)\n",
    "    dunn = dunn_index_mixed(X, clusters, num_idx, cat_idx, gamma)\n",
    "    results.append({'k': k, 'cost': cost, 'silhouette': sil, 'dunn': dunn})\n",
    "    labels_dict[k] = clusters.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6b8651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results summary:\n",
      "    k         cost  silhouette      dunn\n",
      "0   2  1508.287878    0.343990  0.042846\n",
      "1   3  1192.658053    0.313780  0.064269\n",
      "2   4  1001.248250    0.323578  0.142459\n",
      "3   5   863.575150    0.309508  0.143294\n",
      "4   6   789.279665    0.279893  0.058987\n",
      "5   7   749.930065    0.251352  0.157874\n",
      "6   8   713.839153    0.297305  0.232749\n",
      "7   9   690.999616    0.268088  0.088480\n",
      "8  10   657.416967    0.254090  0.168475\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResults summary:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ccfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2: [121  79]\n",
      "k = 3: [74 57 69]\n",
      "k = 4: [73 50 41 36]\n",
      "k = 5: [51 35 44 29 41]\n",
      "k = 6: [31 21 35 41 34 38]\n",
      "k = 7: [35 29 12 38 20 35 31]\n",
      "k = 8: [37 29 33 16 10 42 13 20]\n"
     ]
    }
   ],
   "source": [
    "k_values = range(2, 9)\n",
    "\n",
    "cluster_distributions = []  \n",
    "\n",
    "for k in k_values:\n",
    "    model = KPrototypes(n_clusters=k, random_state=42)\n",
    "    clusters = model.fit_predict(X, categorical=cat_idx)\n",
    "    \n",
    "    counts = pd.Series(clusters).value_counts().sort_index().values\n",
    "    cluster_distributions.append(counts)\n",
    "\n",
    "for k, dist in zip(k_values, cluster_distributions):\n",
    "    print(f\"k = {k}: {dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7f2f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Variasi Tiap Cluster:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>numeric_var</th>\n",
       "      <th>categorical_var</th>\n",
       "      <th>total_cluster_variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.533445</td>\n",
       "      <td>1.559209</td>\n",
       "      <td>1.046327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.391454</td>\n",
       "      <td>1.368864</td>\n",
       "      <td>0.880159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500485</td>\n",
       "      <td>1.317892</td>\n",
       "      <td>0.909188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.377912</td>\n",
       "      <td>1.617111</td>\n",
       "      <td>0.997511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  numeric_var  categorical_var  total_cluster_variation\n",
       "0        0     0.533445         1.559209                 1.046327\n",
       "1        1     0.391454         1.368864                 0.880159\n",
       "2        2     0.500485         1.317892                 0.909188\n",
       "3        3     0.377912         1.617111                 0.997511"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Model Variation Score (k=4): 0.9583\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "k_optimal = 4\n",
    "clusters = labels_dict[k_optimal]\n",
    "\n",
    "# Pastikan DataFrame\n",
    "df = pd.DataFrame(X).copy()\n",
    "df['cluster'] = clusters.astype(int)\n",
    "\n",
    "# Kolom numerik & kategorikal\n",
    "numeric_cols = [df.columns[i] for i in num_idx]\n",
    "categorical_cols = [df.columns[i] for i in cat_idx]\n",
    "\n",
    "results = []\n",
    "\n",
    "for c in sorted(df['cluster'].unique()):\n",
    "    df_c = df[df['cluster'] == c]\n",
    "\n",
    "    # ====== Numeric STD ======\n",
    "    numeric_std = df_c[numeric_cols].std()\n",
    "\n",
    "    # Normalisasi ke 0-1 (min-max std across ALL clusters)\n",
    "    std_norm = (numeric_std - numeric_std.min()) / (numeric_std.max() - numeric_std.min())\n",
    "    numeric_variation = std_norm.mean()  # rata rata variasi numerik cluster\n",
    "\n",
    "    # ====== Categorical Variance (Entropy) ======\n",
    "    entropies = []\n",
    "    for col in categorical_cols:\n",
    "        probs = df_c[col].value_counts(normalize=True)\n",
    "        entropies.append(entropy(probs, base=2))  # log base-2 â†’ skala 0â€“1\n",
    "    \n",
    "    categorical_variation = np.mean(entropies)\n",
    "\n",
    "    # ===== Total Variation per cluster =====\n",
    "    total_variation = (numeric_variation + categorical_variation) / 2\n",
    "\n",
    "    results.append({\n",
    "        \"cluster\": c,\n",
    "        \"numeric_var\": numeric_variation,\n",
    "        \"categorical_var\": categorical_variation,\n",
    "        \"total_cluster_variation\": total_variation\n",
    "    })\n",
    "\n",
    "variation_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"ðŸ“Œ Variasi Tiap Cluster:\")\n",
    "display(variation_df)\n",
    "\n",
    "# ===== Model Variation Score =====\n",
    "model_variation_score = variation_df[\"total_cluster_variation\"].mean()\n",
    "print(f\"\\nðŸŽ¯ Model Variation Score (k={k_optimal}): {model_variation_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
